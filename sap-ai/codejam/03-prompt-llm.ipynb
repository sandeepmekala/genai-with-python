{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your connection to Generative AI Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è In the init_env.py file the values from `generative-ai-codejam/.aicore-config.json` are assigned to environmental variables. That way the Generative AI Hub [Python SDK](https://pypi.org/project/generative-ai-hub-sdk/) will connect to Generative AI Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ For the Python SDK to know which resource group to use, you also need to set the `resource group` in the [`variables.py`](variables.py) file to your own `resource group` (e.g. **team-01**) that you created in the SAP AI Launchpad in exercise [00-connect-AICore-and-AILaunchpad](00-connect-AICore-and-AILaunchpad.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource group is set to: default\n"
     ]
    }
   ],
   "source": [
    "import init_env\n",
    "import variables\n",
    "import importlib\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "# TODO: You need to specify which model you want to use. In this case we are directing our prompt\n",
    "# to the openAI API directly so you need to pick one of the GPT models. Make sure the model is actually deployed\n",
    "# in genAI Hub. You might also want to chose a model that can also process images here already. \n",
    "# E.g. 'gpt-4.1-mini'\n",
    "MODEL_NAME = 'gpt-4.1-mini'\n",
    "# Do not modify the `assert` line below\n",
    "assert MODEL_NAME!='', \"\"\"You should change the variable `MODEL_NAME` with the name of your deployed model (like 'gpt-4o-mini') first!\"\"\"\n",
    "\n",
    "init_env.set_environment_variables()\n",
    "# Do not modify the `assert` line below \n",
    "assert variables.RESOURCE_GROUP!='', \"\"\"You should change the value assigned to the `RESOURCE_GROUP` in the `variables.py` file to your own resource group first!\"\"\"\n",
    "print(f\"Resource group is set to: {variables.RESOURCE_GROUP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt an LLM in the Generative AI Hub...\n",
    "\n",
    "...using OpenAI native client integration: https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/gen_ai_hub.html#openai\n",
    "\n",
    "To understand the API and structures, check OpenAI documentation: https://platform.openai.com/docs/guides/text?api-mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "An LLM (Large Language Model) is typically based on the Transformer architecture, which uses layers of self-attention and feed-forward neural networks to process and generate language by capturing contextual relationships in sequential data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "from IPython.display import Markdown\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model architecture of an LLM? Explain it as short as possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(model_name=MODEL_NAME, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding roles\n",
    "Most LLMs have the roles `system`, `assistant` (GPT) or `model` (Gemini) and `user` that can be used to steer the models response. In the previous step you only used the role `user` to ask your question. \n",
    "\n",
    "üëâ Try out different `system` messages to change the response. You can also tell the model to not engage in smalltalk or only answer questions on a certain topic. Then try different user prompts as well!\n",
    "\n",
    "Please note, that in OpenAI API with `o1` models and newer, `developer` messages replace the previous `system` messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Arrr! The secret sea chart of an LLM be the Transformer architecture ‚Äî a mighty fleet o‚Äô layers usin‚Äô attention mechanisms to weigh every word in the treasure map (text) and steer the ship toward smart, crafty responses!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {   \"role\": \"system\", \n",
    "        # TODO try changing the system prompt\n",
    "        \"content\": \"Speak like a Pirate.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is the underlying model architecture of an LLM? Explain it as short as possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(model_name=MODEL_NAME, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Also try to have it speak like a pirate.\n",
    "\n",
    "üëâ Now let's be more serious! Tell it to behave like an SAP consultant talking to AI Developers.\n",
    "\n",
    "üëâ Ask it to behave like an SAP Consultant talking to ABAP Developers and to make ABAP comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucinations\n",
    "üëâ Run the following question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In SAP Integration Suite (orchestration service), data masking is used to protect sensitive information during message processing and monitoring. Here‚Äôs how data masking works in the orchestration service:\n",
       "\n",
       "1. **Configuration of Data Masking Rules**:  \n",
       "   You define data masking rules that specify which elements or fields in the message payload or headers should be masked. These rules are based on XPath expressions or JSONPath to precisely identify sensitive data locations within the message structure.\n",
       "\n",
       "2. **Masking during Message Processing**:  \n",
       "   When a message passes through the orchestration (integration flow), the service applies these masking rules to the message content, replacing sensitive data with masked values (e.g., asterisks or generic placeholder strings). This occurs before the message is stored in message monitoring or logs.\n",
       "\n",
       "3. **Data Masking in Message Monitoring and Logs**:  \n",
       "   The primary purpose of data masking is to avoid sensitive information exposure in message monitoring tools, logs, and tracing. The original data remains intact during runtime but is masked in the UI and logs where users can access the messages, ensuring compliance with data privacy and security standards.\n",
       "\n",
       "4. **Scope of Masking**:  \n",
       "   Masking can be applied to various data types, including XML, JSON, and plain text messages. This gives flexibility to secure data across different integration scenarios.\n",
       "\n",
       "5. **No Impact on Message Processing**:  \n",
       "   The masking is non-intrusive for the actual processing; it only affects how data is displayed in monitoring or logging interfaces but does not alter the message payload that is sent to the target system.\n",
       "\n",
       "**Summary**: The orchestration service applies configured data masking rules to sensitive fields within messages during processing, masking them in logs and monitoring views without modifying the actual message content sent downstream. This ensures sensitive data protection and compliance with data privacy regulations.\n",
       "\n",
       "If you want, I can provide details on how to configure these masking rules or where to manage them in the SAP Integration Suite."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {   \"role\": \"system\", \n",
    "        \"content\": \"You are an SAP Consultant.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"How does the data masking of the orchestration service work?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "kwargs = dict(model_name=MODEL_NAME, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Compare the response to [SAP Help - Generative AI Hub SDK](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html). \n",
    "\n",
    "üëâ What did the model respond? Was it the truth or a hallucination?\n",
    "\n",
    "üëâ Which questions work well, which questions still do not work so well?\n",
    "\n",
    "# Use Multimodal Models\n",
    "\n",
    "Multimodal models can use different inputs such as text, audio and [images](https://platform.openai.com/docs/guides/images-vision?api-mode=chat&format=base64-encoded#giving-a-model-images-as-input). In Generative AI Hub on SAP AI Core you can access multiple multimodal models (e.g. `gpt-4o-mini`).\n",
    "\n",
    "üëâ If you have not deployed one of the gpt-4o-mini models in previous exercises, then go back to the model library and deploy a model that can also process images.\n",
    "\n",
    "üëâ Now run the code snippet below to get a description for [the image of the AI Foundation Architecture](documents/ai-foundation-architecture.png). These descriptions can then for example be used as alternative text for screen readers or other assistive tech.\n",
    "\n",
    "üëâ You can upload your own image and play around with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image is a detailed architecture diagram titled \"Single-tenant application (Retrieval Augmented Generation & Generative AI on SAP BTP).\" It illustrates the components and interactions within SAP BTP (Business Technology Platform) for building an AI-enhanced single-tenant application.\n",
       "\n",
       "- On the left, a User icon connects to \"Application Clients\" representing Mobile/Desktop devices.\n",
       "- The application clients connect to the \"HTML5 App Repository\" and then to an \"App Router\" within a \"Subaccount\" labeled \"Multi-Cloud.\"\n",
       "- The Subaccount contains several components:\n",
       "   - \"User Interface\" with SAPUI5 and UI5 Web Components listed.\n",
       "   - \"SAP Authorization and Trust Management service\" managing trust relationships (represented with green arrows labeled \"Trust\").\n",
       "   - \"SAP Continuous Integration and Delivery\" and \"SAP Business Application Studio\" icons below.\n",
       "   - The \"SAP Cloud Application Programming Model (CAP)\" box in pink includes an \"Application Service\" with Use Case Logic, Data Management, LLM Plugins & SDKs, and SAP Cloud SDK for AI.\n",
       "   - A connection heads to \"SAP HANA Cloud\" with \"Vector Engine\" highlighted.\n",
       "   - The \"Generative AI Hub\" box in pink includes:\n",
       "       - \"SAP AI Launchpad\"\n",
       "       - \"SAP AI Core\" with Trust & Control and Prompt Registry\n",
       "       - \"Orchestration\" with Grounding, Templating, Data Masking, and I/O Filtering\n",
       "       - \"Foundation Model Access\" indicating \"Partner built\" (active) and \"SAP built\" (grayed out)\n",
       "       - \"Foundation Models\" labeled SAP hosted.\n",
       "- The Generative AI Hub connects via HTTPS to various external entities under \"NETWORK\":\n",
       "   - \"SAP On-Premise Solutions\" using Cloud Connector.\n",
       "   - \"3rd Party Applications\"\n",
       "   - \"SAP Cloud Solutions\"\n",
       "- The diagram includes numbered callouts (1, 2, 3) depicting flow between components:\n",
       "   1. From Application Clients to CAP and then to Generative AI Hub (using Harmonized API).\n",
       "   2. From CAP to SAP HANA Cloud.\n",
       "   3. From Generative AI Hub back to CAP.\n",
       "- A legend explains icons: Blue circles represent Access, Green arrows denote Mutual Trust, and a blue icon shows SAP BTP Service. There's also a note about Foundation Models being partner hosted or SAP hosted.\n",
       "- The diagram level is L2 with a note stating that this BTP Solution Diagram describes how to seamlessly combine various Large Language Models (LLMs) using the Generative AI Hub in SAP AI Core.\n",
       "\n",
       "Overall, the diagram presents a high-level architecture for integrating user-facing applications with backend AI services and foundation models on SAP's cloud platform."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "# get the image from the documents folder\n",
    "with open(\"documents/ai-foundation-architecture.png\", \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "messages = [{\n",
    "            \"role\": \"user\", \n",
    "             \"content\": [\n",
    "                {\"type\": \"text\", \n",
    "                 \"text\": \"Describe the images as an alternative text.\"},\n",
    "                {\"type\": \"image_url\", \n",
    "                 \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{image_data}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "kwargs = dict(model_name=MODEL_NAME, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text from images\n",
    "Nora loves bananabread and thinks recipes are a good example of how LLMs can also extract complex text from images, like from [a picture of a recipe of a bananabread](documents/bananabread.png). Try your own recipe if you like :)\n",
    "\n",
    "This exercise also shows how you can use the output of an LLM in other systems, as you can tell the LLM how to output information, for example in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the extracted contents in two separate JSON files:\n",
       "\n",
       "**ingredients.json**\n",
       "```json\n",
       "{\n",
       "  \"Dry Ingredients\": {\n",
       "    \"All-purpose Flour\": \"260 g\",\n",
       "    \"Sugar\": \"200 g\",\n",
       "    \"Baking Soda\": \"6 g\",\n",
       "    \"Salt\": \"3 g\"\n",
       "  },\n",
       "  \"Wet Ingredients\": {\n",
       "    \"Banana\": \"225 g\",\n",
       "    \"Large Eggs\": \"2\",\n",
       "    \"Vegetable Oil\": \"100 g\",\n",
       "    \"Whole Milk\": \"55 g\",\n",
       "    \"Vanilla Extract\": \"5 g\"\n",
       "  },\n",
       "  \"Toppings\": {\n",
       "    \"Chocolate Chips\": \"100 g\",\n",
       "    \"Walnuts (Optional)\": \"100 g\"\n",
       "  }\n",
       "}\n",
       "```\n",
       "\n",
       "**instructions.json**\n",
       "```json\n",
       "{\n",
       "  \"Directions\": [\n",
       "    \"Preheat oven to 180 ¬∞C\",\n",
       "    \"Mash banana in a bowl\",\n",
       "    \"Combine banana and other wet ingredients together in the same bowl\",\n",
       "    \"Mix all dry ingredients together in a separate bowl\",\n",
       "    \"Use a whisk to combine dry mixture into wet mixture until smooth\",\n",
       "    \"Pour mixture into a greased/buttered loaf pan\",\n",
       "    \"Place the pan into preheated oven on the middle rack and bake for about 60 minutes or until a toothpick comes out clean\",\n",
       "    \"Enjoy!\"\n",
       "  ]\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the image from the documents folder\n",
    "with open(\"documents/bananabread.png\", \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "messages = [{\"role\": \"user\", \n",
    "             \"content\": [\n",
    "                {\"type\": \"text\", \n",
    "                \"text\": \"Extract the ingredients and instructions in two different json files.\"},\n",
    "                {\"type\": \"image_url\", \n",
    "                 \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{image_data}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "kwargs = dict(model_name=MODEL_NAME, messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next exercise](04-create-embeddings.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
