{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Memory\n",
    "\n",
    "Let's add some history to the interaction and build a chatbot. Unlike many people think. LLMs are fixed in their state. They are trained until a certain cutoff date and do not know anything after that point unless you feed them current information. That is also why LLMs do not remember anything about you or the prompts you send to the model. If the model seems to remember you and what you said it is always because the application you are using (e.g. ChatPGT or the chat function in SAP AI Launchpad) is sending the chat history to the model to provide the conversation history to the model as context.\n",
    "\n",
    "Below you can find a simple implementation of a chatbot with memory.\n",
    "\n",
    "The code in this exercise is based on the [help documentation](https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/orchestration-service.html) of the Generative AI Hub Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import variables\n",
    "from typing import List\n",
    "\n",
    "init_env.set_environment_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import Message, SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the chatbot class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful chatbot assistant.\"),\n",
    "                    UserMessage(\"{{?user_query}}\"),\n",
    "                ],\n",
    "            ),\n",
    "            # TODO add a model name here, e.g. gemini-1.5-flash\n",
    "            llm=LLM(name='gpt-4.1-mini'),\n",
    "        )\n",
    "        self.history: List[Message] = []\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"user_query\", value=user_input),\n",
    "            ],\n",
    "            history=self.history,\n",
    "        )\n",
    "\n",
    "        message = response.orchestration_result.choices[0].message\n",
    "\n",
    "        self.history = response.module_results.templating\n",
    "        self.history.append(message)\n",
    "\n",
    "        return message.content\n",
    "    \n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "service = OrchestrationService(api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL)\n",
    "bot = ChatBot(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! Yes, I'm here. How can I assist you today?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chat(\"Hello, are you there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think CodeJams are great! They're a fun way to challenge your programming skills, learn new techniques, and connect with other coders. Do you participate in CodeJams?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chat(\"Do you like CodeJams?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, we first talked about whether I like CodeJams. Is there something specific you'd like to continue discussing about them?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chat(\"Can you remember what we first talked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(role=<Role.SYSTEM: 'system'>, content='You are a helpful chatbot assistant.'),\n",
       " Message(role=<Role.USER: 'user'>, content='Hello, are you there?'),\n",
       " Message(role=<Role.ASSISTANT: 'assistant'>, content=\"Hello! Yes, I'm here. How can I assist you today?\"),\n",
       " Message(role=<Role.SYSTEM: 'system'>, content='You are a helpful chatbot assistant.'),\n",
       " Message(role=<Role.USER: 'user'>, content='Do you like CodeJams?'),\n",
       " Message(role=<Role.ASSISTANT: 'assistant'>, content=\"I think CodeJams are great! They're a fun way to challenge your programming skills, learn new techniques, and connect with other coders. Do you participate in CodeJams?\"),\n",
       " Message(role=<Role.SYSTEM: 'system'>, content='You are a helpful chatbot assistant.'),\n",
       " Message(role=<Role.USER: 'user'>, content='Can you remember what we first talked about?'),\n",
       " Message(role=<Role.ASSISTANT: 'assistant'>, content=\"Yes, we first talked about whether I like CodeJams. Is there something specific you'd like to continue discussing about them?\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to prove to you that the model does indeed not remember you, let's delete the history and try again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I donâ€™t have the ability to remember previous parts of our conversation once the session ends. However, I can keep track of what we discuss during this session. How can I assist you today?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.reset()\n",
    "bot.chat(\"Can you remember what we first talked about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next exercise](11-your-chatbot.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
